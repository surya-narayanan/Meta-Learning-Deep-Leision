{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DeepLesion(mode='test')\n",
    "\n",
    "spl = dataset[0]\n",
    "print(spl['y'])\n",
    "plt.imshow(spl['x'])\n",
    "\n",
    "root_dir='/home/Surya/Meta-Learning-Deep-Leision/'\n",
    "mode = 'test'\n",
    "\n",
    "with open( root_dir + 'X_' + mode + '.p', 'rb' ) as f:\n",
    "    X = pickle.load(f)\n",
    "    X = np.transpose(X, (0,3,1,2))\n",
    "    \n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import pickle\n",
    "import gc\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import learn2learn as l2l\n",
    "from learn2learn.data import MetaDataset, TaskDataset\n",
    "from learn2learn.data.transforms import NWays, KShots, LoadData, RemapLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepLesion(Dataset):\n",
    "\n",
    "    def __init__(self, mode, root_dir='/home/Surya/Meta-Learning-Deep-Leision/', transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            pickle_file (string): Path to the file with datasets.\n",
    "            mode (string): Train or Val or Test.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        x = 'X_train.p'\n",
    "        y = 'Y_train.p'\n",
    "        with open( root_dir + 'X_' + mode + '.p', 'rb' ) as f:\n",
    "            self.X = pickle.load(f)\n",
    "        with open( root_dir + 'Y_' + mode + '.p', 'rb' ) as f:\n",
    "            self.Y = pickle.load(f)\n",
    "        self.X = np.float32(self.X)\n",
    "        self.X = np.transpose(self.X, (0,3,1,2))\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.Y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        x = self.X[idx]\n",
    "        y = self.Y[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(x)\n",
    "\n",
    "        return np.float32(x), int(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairwise_distances_logits(a, b):\n",
    "    n = a.shape[0]\n",
    "    m = b.shape[0]\n",
    "    logits = -((a.unsqueeze(1).expand(n, m, -1) -\n",
    "                b.unsqueeze(0).expand(n, m, -1))**2).sum(dim=2)\n",
    "    return logits\n",
    "\n",
    "\n",
    "def accuracy(predictions, targets):\n",
    "    predictions = predictions.argmax(dim=1).view(targets.shape)\n",
    "    return (predictions == targets).sum().float() / targets.size(0)\n",
    "\n",
    "\n",
    "class Convnet(nn.Module):\n",
    "\n",
    "    def __init__(self, x_dim=3, hid_dim=64, z_dim=64):\n",
    "        super().__init__()\n",
    "        self.encoder = l2l.vision.models.ConvBase(output_size=z_dim,\n",
    "                                                  hidden=hid_dim,\n",
    "                                                  channels=x_dim)\n",
    "        self.out_channels = 1600\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        return x.view(x.size(0), -1)\n",
    "\n",
    "\n",
    "def fast_adapt(model, batch, ways, shot, query_num, metric=None, device=None):\n",
    "    if metric is None:\n",
    "        metric = pairwise_distances_logits\n",
    "    if device is None:\n",
    "        device = model.device()\n",
    "    data, labels = batch\n",
    "    data = data.to(device)\n",
    "    labels = labels.to(device)\n",
    "    n_items = shot * ways\n",
    "\n",
    "    # Sort data samples by labels\n",
    "    # TODO: Can this be replaced by ConsecutiveLabels ?\n",
    "    sort = torch.sort(labels)\n",
    "    data = data.squeeze(0)[sort.indices].squeeze(0)\n",
    "    labels = labels.squeeze(0)[sort.indices].squeeze(0)\n",
    "\n",
    "    # Compute support and query embeddings\n",
    "    embeddings = model(data)\n",
    "    support_indices = np.zeros(data.size(0), dtype=bool)\n",
    "    selection = np.arange(ways) * (shot + query_num)\n",
    "    for offset in range(shot):\n",
    "        support_indices[selection + offset] = True\n",
    "    query_indices = torch.from_numpy(~support_indices)\n",
    "    support_indices = torch.from_numpy(support_indices)\n",
    "    support = embeddings[support_indices]\n",
    "    support = support.reshape(ways, shot, -1).mean(dim=1)\n",
    "    query = embeddings[query_indices]\n",
    "    labels = labels[query_indices].long()\n",
    "\n",
    "    logits = pairwise_distances_logits(query, support)\n",
    "    loss = F.cross_entropy(logits, labels)\n",
    "    acc = accuracy(logits, labels)\n",
    "    return loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--max-epoch', type=int, default=10)\n",
    "parser.add_argument('--shot', type=int, default=5)\n",
    "parser.add_argument('--test-way', type=int, default=5)\n",
    "parser.add_argument('--test-shot', type=int, default=5)\n",
    "parser.add_argument('--test-query', type=int, default=1)\n",
    "parser.add_argument('--train-query', type=int, default=15)\n",
    "parser.add_argument('--train-way', type=int, default=5)\n",
    "parser.add_argument('--gpu', default=1)\n",
    "args = parser.parse_args('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, train, loss=1.4211 acc=0.3955\n",
      "epoch 1, val, loss=1.2869 acc=0.4750\n",
      "epoch 2, train, loss=1.3834 acc=0.4039\n",
      "epoch 2, val, loss=1.1972 acc=0.5500\n",
      "epoch 3, train, loss=1.3224 acc=0.4223\n",
      "epoch 3, val, loss=1.2364 acc=0.4750\n",
      "epoch 4, train, loss=1.3185 acc=0.4275\n",
      "epoch 4, val, loss=1.2403 acc=0.4500\n",
      "epoch 5, train, loss=1.2715 acc=0.4368\n",
      "epoch 5, val, loss=1.3038 acc=0.5000\n",
      "epoch 6, train, loss=1.2731 acc=0.4472\n",
      "epoch 6, val, loss=1.1967 acc=0.4750\n",
      "epoch 7, train, loss=1.2945 acc=0.4205\n",
      "epoch 7, val, loss=1.2858 acc=0.3750\n",
      "epoch 8, train, loss=1.2712 acc=0.4373\n",
      "epoch 8, val, loss=1.2726 acc=0.4000\n",
      "epoch 9, train, loss=1.2715 acc=0.4513\n",
      "epoch 9, val, loss=1.1791 acc=0.4500\n",
      "epoch 10, train, loss=1.2905 acc=0.4372\n",
      "epoch 10, val, loss=1.1582 acc=0.4750\n",
      "batch 1: 40.00(40.00)\n",
      "batch 2: 40.00(40.00)\n",
      "batch 3: 40.00(40.00)\n",
      "batch 4: 30.00(0.00)\n",
      "batch 5: 36.00(60.00)\n",
      "batch 6: 33.33(20.00)\n",
      "batch 7: 34.29(40.00)\n",
      "batch 8: 32.50(20.00)\n",
      "batch 9: 33.33(40.00)\n"
     ]
    }
   ],
   "source": [
    "# device = torch.device('cpu')\n",
    "# if args.gpu and torch.cuda.device_count():\n",
    "#     print(\"Using gpu\")\n",
    "#     torch.cuda.manual_seed(43)\n",
    "#     device = torch.device('cuda')\n",
    "\n",
    "# model = Convnet()\n",
    "# model.to(device)\n",
    "\n",
    "# # print('Loading Training Data')\n",
    "# # train_dataset = DeepLesion(mode='train')\n",
    "# # print('Loading Validation Data')\n",
    "# # valid_dataset = DeepLesion(mode='val')\n",
    "# # print('Loading Test Data')\n",
    "# # test_dataset = DeepLesion(mode='test')\n",
    "\n",
    "# train_dataset = l2l.data.MetaDataset(train_dataset)\n",
    "# train_transforms = [\n",
    "#     NWays(train_dataset, args.train_way),\n",
    "#     KShots(train_dataset, args.train_query + args.shot),\n",
    "#     LoadData(train_dataset),\n",
    "#     RemapLabels(train_dataset),\n",
    "# ]\n",
    "# train_tasks = l2l.data.TaskDataset(train_dataset, task_transforms=train_transforms)\n",
    "# train_loader = DataLoader(train_tasks, pin_memory=True, shuffle=True)\n",
    "\n",
    "# valid_dataset = l2l.data.MetaDataset(valid_dataset)\n",
    "# valid_transforms = [\n",
    "#     NWays(valid_dataset, args.test_way),\n",
    "#     KShots(valid_dataset, args.test_query + args.test_shot),\n",
    "#     LoadData(valid_dataset),\n",
    "#     RemapLabels(valid_dataset),\n",
    "# ]\n",
    "\n",
    "# num_tasks_val = math.floor(len(valid_dataset)/(args.test_way*(args.test_query + args.test_shot)))\n",
    "# valid_tasks = l2l.data.TaskDataset(valid_dataset,\n",
    "#                                    task_transforms=valid_transforms,\n",
    "#                                    num_tasks= num_tasks_val)\n",
    "# valid_loader = DataLoader(valid_tasks, pin_memory=True, shuffle=True)\n",
    "\n",
    "# test_dataset = l2l.data.MetaDataset(test_dataset)\n",
    "# test_transforms = [\n",
    "#     NWays(test_dataset, args.test_way),\n",
    "#     KShots(test_dataset, args.test_query + args.test_shot),\n",
    "#     LoadData(test_dataset),\n",
    "#     RemapLabels(test_dataset),\n",
    "# ]\n",
    "\n",
    "num_tasks_test = math.floor(len(test_dataset)/(args.test_way*(args.test_query + args.test_shot)))\n",
    "test_tasks = l2l.data.TaskDataset(test_dataset,\n",
    "                                  task_transforms=test_transforms,\n",
    "                                  num_tasks=num_tasks_test)\n",
    "test_loader = DataLoader(test_tasks, pin_memory=True, shuffle=True)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(\n",
    "    optimizer, step_size=20, gamma=0.5)\n",
    "\n",
    "for epoch in range(1, args.max_epoch + 1):\n",
    "    model.train()\n",
    "\n",
    "    loss_ctr = 0\n",
    "    n_loss = 0\n",
    "    n_acc = 0\n",
    "\n",
    "    for i in range(100):\n",
    "        batch = next(iter(train_loader))\n",
    "\n",
    "        loss, acc = fast_adapt(model,\n",
    "                               batch,\n",
    "                               args.train_way,\n",
    "                               args.shot,\n",
    "                               args.train_query,\n",
    "                               metric=pairwise_distances_logits,\n",
    "                               device=device)\n",
    "\n",
    "        loss_ctr += 1\n",
    "        n_loss += loss.item()\n",
    "        n_acc += acc\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    lr_scheduler.step()\n",
    "\n",
    "    print('epoch {}, train, loss={:.4f} acc={:.4f}'.format(\n",
    "        epoch, n_loss/loss_ctr, n_acc/loss_ctr))\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    loss_ctr = 0\n",
    "    n_loss = 0\n",
    "    n_acc = 0\n",
    "    for i, batch in enumerate(valid_loader):\n",
    "        loss, acc = fast_adapt(model,\n",
    "                               batch,\n",
    "                               args.test_way,\n",
    "                               args.test_shot,\n",
    "                               args.test_query,\n",
    "                               metric=pairwise_distances_logits,\n",
    "                               device=device)\n",
    "\n",
    "        loss_ctr += 1\n",
    "        n_loss += loss.item()\n",
    "        n_acc += acc\n",
    "\n",
    "    print('epoch {}, val, loss={:.4f} acc={:.4f}'.format(\n",
    "        epoch, n_loss/loss_ctr, n_acc/loss_ctr))\n",
    "\n",
    "loss_ctr = 0\n",
    "n_acc = 0\n",
    "\n",
    "for i, batch in enumerate(test_loader, 1):\n",
    "    loss, acc = fast_adapt(model,\n",
    "                           batch,\n",
    "                           args.test_way,\n",
    "                           args.test_shot,\n",
    "                           args.test_query,\n",
    "                           metric=pairwise_distances_logits,\n",
    "                           device=device)\n",
    "    loss_ctr += 1\n",
    "    n_acc += acc\n",
    "    print('batch {}: {:.2f}({:.2f})'.format(\n",
    "        i, n_acc/loss_ctr * 100, acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2994\n",
      "268\n",
      "277\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dataset))\n",
    "print(len(valid_dataset))\n",
    "print(len(test_dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
